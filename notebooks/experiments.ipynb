{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tlab_2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import fire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(fire.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Подготовим список тайтлов фильмов\n",
    "\n",
    "https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\n",
    "\n",
    "Возьмем список из 1000 фильмов отсюда, чтобы не выписывать их самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/imdb_top_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poster_Link</th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Genre</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Star1</th>\n",
       "      <th>Star2</th>\n",
       "      <th>Star3</th>\n",
       "      <th>Star4</th>\n",
       "      <th>No_of_Votes</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMDFkYT...</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>A</td>\n",
       "      <td>142 min</td>\n",
       "      <td>Drama</td>\n",
       "      <td>9.3</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>Tim Robbins</td>\n",
       "      <td>Morgan Freeman</td>\n",
       "      <td>Bob Gunton</td>\n",
       "      <td>William Sadler</td>\n",
       "      <td>2343110</td>\n",
       "      <td>28,341,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BM2MyNj...</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>A</td>\n",
       "      <td>175 min</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Marlon Brando</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>James Caan</td>\n",
       "      <td>Diane Keaton</td>\n",
       "      <td>1620367</td>\n",
       "      <td>134,966,411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTMxNT...</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>UA</td>\n",
       "      <td>152 min</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>9.0</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>Heath Ledger</td>\n",
       "      <td>Aaron Eckhart</td>\n",
       "      <td>Michael Caine</td>\n",
       "      <td>2303232</td>\n",
       "      <td>534,858,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMWMwMG...</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>A</td>\n",
       "      <td>202 min</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>Robert Duvall</td>\n",
       "      <td>Diane Keaton</td>\n",
       "      <td>1129952</td>\n",
       "      <td>57,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMWU4N2...</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>U</td>\n",
       "      <td>96 min</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>Henry Fonda</td>\n",
       "      <td>Lee J. Cobb</td>\n",
       "      <td>Martin Balsam</td>\n",
       "      <td>John Fiedler</td>\n",
       "      <td>689845</td>\n",
       "      <td>4,360,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Poster_Link  \\\n",
       "0  https://m.media-amazon.com/images/M/MV5BMDFkYT...   \n",
       "1  https://m.media-amazon.com/images/M/MV5BM2MyNj...   \n",
       "2  https://m.media-amazon.com/images/M/MV5BMTMxNT...   \n",
       "3  https://m.media-amazon.com/images/M/MV5BMWMwMG...   \n",
       "4  https://m.media-amazon.com/images/M/MV5BMWU4N2...   \n",
       "\n",
       "               Series_Title Released_Year Certificate  Runtime  \\\n",
       "0  The Shawshank Redemption          1994           A  142 min   \n",
       "1             The Godfather          1972           A  175 min   \n",
       "2           The Dark Knight          2008          UA  152 min   \n",
       "3    The Godfather: Part II          1974           A  202 min   \n",
       "4              12 Angry Men          1957           U   96 min   \n",
       "\n",
       "                  Genre  IMDB_Rating  \\\n",
       "0                 Drama          9.3   \n",
       "1          Crime, Drama          9.2   \n",
       "2  Action, Crime, Drama          9.0   \n",
       "3          Crime, Drama          9.0   \n",
       "4          Crime, Drama          9.0   \n",
       "\n",
       "                                            Overview  Meta_score  \\\n",
       "0  Two imprisoned men bond over a number of years...        80.0   \n",
       "1  An organized crime dynasty's aging patriarch t...       100.0   \n",
       "2  When the menace known as the Joker wreaks havo...        84.0   \n",
       "3  The early life and career of Vito Corleone in ...        90.0   \n",
       "4  A jury holdout attempts to prevent a miscarria...        96.0   \n",
       "\n",
       "               Director           Star1           Star2          Star3  \\\n",
       "0        Frank Darabont     Tim Robbins  Morgan Freeman     Bob Gunton   \n",
       "1  Francis Ford Coppola   Marlon Brando       Al Pacino     James Caan   \n",
       "2     Christopher Nolan  Christian Bale    Heath Ledger  Aaron Eckhart   \n",
       "3  Francis Ford Coppola       Al Pacino  Robert De Niro  Robert Duvall   \n",
       "4          Sidney Lumet     Henry Fonda     Lee J. Cobb  Martin Balsam   \n",
       "\n",
       "            Star4  No_of_Votes        Gross  \n",
       "0  William Sadler      2343110   28,341,469  \n",
       "1    Diane Keaton      1620367  134,966,411  \n",
       "2   Michael Caine      2303232  534,858,444  \n",
       "3    Diane Keaton      1129952   57,300,000  \n",
       "4    John Fiedler       689845    4,360,000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df.Series_Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/titles.txt', 'w') as f:\n",
    "        f.write('\\n'.join(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовим промпты\n",
    "\n",
    "Можем использовать достаточно большой список шаблонов для промпта, в том числе в явном виде просить её сгенерировать положительный ответ, отрицательный. Однако, мы не будем пытаться использовать длинные шаблоны промптов, потому что gpt-2 достаточно маленькая, длинные промпты будут плохо действовать на маленьких моделях, и это будет игра с нулевой суммой.\n",
    "\n",
    "Возможно, я неправа в том, что я нарочно прошу генерировать позитивные отзывы напрямую в промпте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_SRC = \"../data/templates.json\"\n",
    "TITLES_SRC = \"../data/titles.txt\"\n",
    "PROMPTS_SRC = \"../data/prompts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.make_dataset import prepate_prompts, prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts = prepate_prompts(300, TEMPLATE_SRC, TITLES_SRC)\n",
    "test_prompts = prepate_prompts(100, TEMPLATE_SRC, TITLES_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/prompts.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/prompts_test.txt', 'w') as f:\n",
    "    f.write('\\n'.join(test_prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Сгенерируем данные при помощи gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 548M/548M [00:22<00:00, 24.1MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 333/333 [00:00<00:00, 1.01MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.52MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 10.9MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 220kB/s]\n",
      "config.json: 100%|██████████| 735/735 [00:00<00:00, 965kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 268M/268M [00:09<00:00, 27.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "gen_tokenizer = transformers.AutoTokenizer.from_pretrained(\"lvwerra/gpt2-imdb\", device_map=device)\n",
    "gen_model = transformers.AutoModelForCausalLM.from_pretrained(\"lvwerra/gpt2-imdb\", device_map=device)\n",
    "if gen_tokenizer.pad_token is None:\n",
    "    gen_tokenizer.pad_token = gen_tokenizer.eos_token\n",
    "\n",
    "reward_tokenizer = transformers.AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "reward_model = transformers.AutoModelForSequenceClassification.from_pretrained(\"lvwerra/distilbert-imdb\", device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/prompts.txt\", \"r\") as f:\n",
    "    prompts = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = gen_tokenizer(prompts,\n",
    "                      return_tensors=\"pt\",\n",
    "                      padding=True).to(device)\n",
    "\n",
    "output = gen_model.generate(**input,\n",
    "                            max_new_tokens=60,\n",
    "                            no_repeat_ngram_size=2,\n",
    "                            do_sample=True,\n",
    "                            temperature=0.25,\n",
    "                            num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 50])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/homebrew/Caskroom/miniconda/base/envs/tlab_2/lib/python3.10/site-packages (from scipy) (1.26.3)\n",
      "Downloading scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl (29.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.11.4\n",
      "1.11.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "\n",
    "import scipy\n",
    "\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
